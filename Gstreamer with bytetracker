print("code running...")
from dronekit import connect, VehicleMode, LocationGlobalRelative
import time, math, torch, numpy as np
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst, GLib

from ByteTrack.yolox.tracker.byte_tracker import BYTETracker
from ByteTrack.yolox.tracking_utils.timer import Timer
from ByteTrack.yolox.exp import get_exp

# ------------------------- Drone Connection -------------------------
vehicle = connect("udp:127.0.0.1:14552", wait_ready=True)
print("Drone connected")
vehicle.mode = VehicleMode("GUIDED")

sensor_width_mm = 7.6
focal_length_mm = 4.6
altitude_m = 10

def arm_and_takeoff(target_altitude):
    while not vehicle.is_armable:
        time.sleep(1)
    vehicle.mode = VehicleMode("GUIDED")
    vehicle.armed = True
    while not vehicle.armed:
        time.sleep(1)
    vehicle.simple_takeoff(target_altitude)
    while True:
        if vehicle.location.global_relative_frame.alt >= target_altitude * 0.95:
            break
        time.sleep(1)

# ------------------------- ByteTrack Setup -------------------------
class TrackerArgs:
    track_thresh = 0.3
    match_thresh = 0.9
    track_buffer = 60
    mot20 = False

args = TrackerArgs()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load YOLOX model
exp_file = "ByteTrack/exps/example/mot/yolox_x_mix_det.py"
ckpt_path = "ByteTrack/pretrained/bytetrack_x_mot17.pth.tar"
exp = get_exp(exp_file, "bytetrack")
model = exp.get_model().to(device)
model.eval()
ckpt = torch.load(ckpt_path, map_location=device)
model.load_state_dict(ckpt["model"])
print("YOLOX + ByteTrack model loaded")

tracker = BYTETracker(args, frame_rate=30)
timer = Timer()

# ------------------------- Drone Utility Functions -------------------------
def get_target_location(current_location, offset_x_m, offset_y_m, alt1=altitude_m):
    R = 6378137.0
    dLat = offset_y_m / R
    dLon = offset_x_m / (R * math.cos(math.pi * current_location.lat / 180.0))
    newlat = current_location.lat + (dLat * 180 / math.pi)
    newlon = current_location.lon + (dLon * 180 / math.pi)
    return LocationGlobalRelative(newlat, newlon, alt1)

def get_distance_meters(loc1, loc2):
    dlat = loc2.lat - loc1.lat
    dlon = loc2.lon - loc1.lon
    return math.sqrt((dlat * 1.113195e5)**2 + (dlon * 1.113195e5)**2)

def camera_to_uav(x_cam, y_cam):
    return -y_cam, x_cam

def uav_to_ne(x_uav, y_uav, yaw_rad):
    c, s = math.cos(yaw_rad), math.sin(yaw_rad)
    return x_uav*c - y_uav*s, x_uav*s + y_uav*c

# ------------------------- GStreamer Setup -------------------------
Gst.init(None)
pipeline_str = (
    "rtspsrc location=rtsp://192.168.144.25:8554/main.264 latency=0 ! "
    "rtph264depay ! h264parse ! avdec_h264 ! videoconvert ! "
    "video/x-raw,format=RGB ! appsink name=appsink0 drop=1 max-buffers=1 sync=false"
)
pipeline = Gst.parse_launch(pipeline_str)
appsink = pipeline.get_by_name("appsink0")
appsink.set_property("emit-signals", True)

# ------------------------- Frame Handler -------------------------
def on_new_sample(sink, data):
    sample = sink.emit("pull-sample")
    if not sample:
        return Gst.FlowReturn.ERROR

    buf = sample.get_buffer()
    caps = sample.get_caps()
    width = caps.get_structure(0).get_value("width")
    height = caps.get_structure(0).get_value("height")

    # Convert buffer â†’ numpy
    success, map_info = buf.map(Gst.MapFlags.READ)
    if not success:
        return Gst.FlowReturn.ERROR
    frame = np.frombuffer(map_info.data, dtype=np.uint8).reshape((height, width, 3))
    buf.unmap(map_info)

    # ------------------------- YOLOX Preprocess -------------------------
    img = frame.astype(np.float32) / 255.0
    img = torch.from_numpy(img).permute(2,0,1).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img)

    # ------------------------- Detections -------------------------
    detections = []
    if outputs[0] is not None:
        dets = outputs[0].detach().cpu().numpy()
        for det in dets:
            x1, y1, x2, y2, score, cls_id = det
            if int(cls_id) == 0:  # only person
                detections.append([x1, y1, x2, y2, score])
    detections = np.array(detections, dtype=np.float32)

    # ------------------------- Tracking -------------------------
    if len(detections) > 0:
        timer.tic()
        online_targets = tracker.update(
            detections, [frame.shape[0], frame.shape[1]], [frame.shape[0], frame.shape[1]]
        )
        timer.toc()
    else:
        online_targets = []

    # ------------------------- Drone Navigation -------------------------
    for t in online_targets:
        tlwh = t.tlwh
        track_id = t.track_id
        x, y, w, h = map(int, tlwh)
        object_centerx = x + w//2
        object_centery = y + h//2

        image_centerx = frame.shape[1] // 2
        image_centery = frame.shape[0] // 2

        GSD = (sensor_width_mm * vehicle.location.global_relative_frame.alt) / (focal_length_mm * frame.shape[1])
        offset_x_m = (object_centerx - image_centerx) * GSD
        offset_y_m = (object_centery - image_centery) * GSD

        x_uav, y_uav = camera_to_uav(offset_x_m, offset_y_m)
        yaw_rad = math.radians(vehicle.heading)
        north_offset, east_offset = uav_to_ne(x_uav, y_uav, yaw_rad)

        current_location = vehicle.location.global_relative_frame
        target_location = get_target_location(current_location, north_offset, east_offset)
        distance = get_distance_meters(current_location, target_location)

        print(f"ID {track_id} | Offset X={offset_x_m:.2f}, Y={offset_y_m:.2f} | Distance={distance:.2f}")
        vehicle.simple_goto(target_location)

    return Gst.FlowReturn.OK

appsink.connect("new-sample", on_new_sample, None)

# ------------------------- Takeoff + Start -------------------------
arm_and_takeoff(altitude_m)
pipeline.set_state(Gst.State.PLAYING)

loop = GLib.MainLoop()
try:
    loop.run()
except KeyboardInterrupt:
    print("Stopping...")
    loop.quit()
    pipeline.set_state(Gst.State.NULL)
    vehicle.close()
